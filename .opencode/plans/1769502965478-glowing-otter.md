# Plan: Implement 4-Stage Federal Register Pipeline Architecture

## Goal

Refactor into 4 separate CLI applications as documented in `docs/federal-register-pipeline.md`.

## Architecture (from docs)

```
backend/cmd/scraper/       → raw_policy_documents (new)
backend/cmd/canonicalize/  → policy_documents (new)
backend/cmd/enrichment/    → policy_documents AI fields (new)
backend/cmd/materialize/   → feed_entries (new)
```

Each CLI is a batch processor: processes all pending records, then exits.

## Orchestration

`backend/scripts/run-pipeline.sh` runs the 4 CLIs sequentially:

```
./scraper && ./canonicalize && ./enrichment && ./materialize
```

## Output Tables & Input Triggers


| Command      | Input                                      | Output                                      |
| ------------ | ------------------------------------------ | ------------------------------------------- |
| scraper      | Federal Register API                       | `raw_policy_documents` (new/updated)        |
| canonicalize | `raw_policy_documents` (all)               | `policy_documents`, sets raw as `processed` |
| enrichment   | `policy_documents` (unenriched)            | Updates AI fields                           |
| materialize  | `policy_documents` (missing/outdated feed) | `feed_entries`                              |


## Files to Create

### New CLI Applications

- `backend/cmd/canonicalize/main.go`
- `backend/cmd/enrichment/main.go`
- `backend/cmd/materialize/main.go`

### Orchestration Script

- `backend/scripts/run-pipeline.sh`

### Shared Logic (existing locations)

- `backend/internal/services/raw_ingestion_service.go`
- `backend/internal/services/canonicalization_service.go`
- `backend/internal/services/enrichment_service.go`
- `backend/internal/services/materialization_service.go`

### Repository Updates

- `raw_policy_documents`: add `status` column (pending|processed|failed), `source_key`, `external_id`
- `policy_documents`: add `unique_key`, `enrichment_status`
- Status columns enable polling and retry logic

## Implementation

### Step 1: Database Migrations

Add status columns for polling:

- `policy_documents.enrichment_status` (default 'pending')

### Step 2: Create 4 CLI Entrypoints

Each is a batch processor that processes all pending records then exits:

```go
func main() {
    ctx := context.Background()
    log.Println("Starting...")

    for {
        records := fetchPending(ctx, limit=100)
        if len(records) == 0 {
            break // No more work, exit
        }

        for _, r := range records {
            if err := process(ctx, r); err != nil {
                markFailed(ctx, r.ID, err)
            } else {
                markProcessed(ctx, r.ID)
            }
        }
    }

    log.Println("Done.")
}
```

### Step 3: Services

Implement the processing logic for each stage:

- `RawIngestionService`: Fetch from FR API, write to raw_policy_documents
- `CanonicalizationService`: Read raw, write policy_documents, update raw status
- `EnrichmentService`: Read policy_documents, call Grok, update AI fields
- `MaterializationService`: Read policy_documents, write feed_entries

### Step 4: Idempotency (per docs)

- scraper: UPSERT on (`source_key`, `external_id`)
- canonicalize: UPSERT on `unique_key`
- enrichment: only write AI fields when NULL/empty
- materialize: UPSERT on `policy_document_id`

## Makefile Updates

Add commands for each stage:

```make
dev-canonicalize: ...
dev-enrichment: ...
dev-materialize: ...
```

## Verification

1. Run migrations
2. Start each CLI in separate terminals
3. Verify end-to-end flow: FR API → raw → canonical → enrich → feed_entries
4. Test re-run idempotency

